# Face Recognition
  - 遇到问题请联系明明老师微信：13271929138
  - gitee地址:https://gitee.com/mingminglaoshi/famous-enterprises-fr-20210828
## week17/1

```
作业：
   [必做]1. 完成人脸识别活体检测前的步骤：人脸检测+关键点提取程序。
    作业步骤：
         1 参考课上的代码示范例子:dlib_detect_recognize_display_show-master,完成代码famous-enterprises-fr-20210828/week1/homework/week1_homework.py的填空。【第26行填空]使用检测模型对图片进行人脸检测，[第29行填空] 对检测到的人脸提取人脸关键点， #[第33行填空] 人脸对齐。
         2 完成后，从网站https://thispersondoesnotexist.com 上，下载一张人脸图片，对此图片存储为person_not_exist.jpg 
         3 运行作业代码，得到人脸检测和关键点的结果图片week1_detect_landmark.jpg，得到人脸对齐后的图片week1_align.jpg
    作业要求：
         1 提交内容：完成填空的代码；自己的person_not_exist.jpg 以及 自己运行代码，得到的结果图片：week1_detect_landmark.jpg 和 week1_align.jpg
         2 代码填写正确可运行。给出图片结果正确。
         本作业在week2课前讲解。
   [选做]2. 用opencv的检测模型，深度学习的检测模型替换dlib模型。
    建议步骤：
          1. 以"cv2人脸检测"为关键字，在搜索引擎上搜索相应内容。应该有很多相关文章以及代码可以参考。
          2. 以“深度学习 人脸检测" 为关键字，在搜索引擎上搜索相应内容。
   [选做]3. 求y=x^2的最小值，用梯度下降的方法，不使用框架
          本作业在week2课前讲解。
   [选做]4. 用框架pytorch求出loss=(5*w_1+3w_2-1)^2+(-3*w1-4*w_2+1)^2的最小值，用梯度下降的方法.
          本作业在week2课前讲解。
   课程资料：
    人脸识别全流程示例代码：dlib_detect_recognize_display_show-master
    人脸识别综述：deepfacerecognition.pdf
    人脸关键点经典方法FPS3000：CVPR14_FaceAlignment.pdf
    活体检测算法2020年综述：https://zhuanlan.zhihu.com/p/114313640
    活体检测算法2019年综述：cvpr2019活体检测进展.pdf
    homework:待填空作业代码
```


## week18/2
```
CV名企实战 :  活体检测模型：facebagnet
https://gitee.com/mingminglaoshi/famous-enterprises-fr-20210828

Pipeline:
1. 二分类做活体检测
2. Patch-based feature:块特征
3. Multi-stream fusion with MFE:多模态擦除式融合
4. FacebagNet模型，以及其train与inference
5. 快照集成：训练1个，得到M个

作业：
   [必做]1. 完成小样本模型的训练。在/week2/week2_homework/内的train.py,model_baseline_Fusion.py内填空。
        2. 提交内容：完成填空后的代码 运行成功后的截图。
   作业说明：
      0. train_data文件夹是少量供测试的图片，含有几组real和fake的3个模态：RGB,depth,IR的图片。可训练的图片路径列表在/week2/week2_homework/train_list_small.txt
      1. 在/week2/week2_homework/tain.py 的28行需填空，添加loss函数
      2. 在/week2/week2_homework/model_baseline_Fusion.py 的 第34行 #[需填空] 声明模型的res_4,res_5,填入成成res_4,res_5所需要的参数；第70行#[需填空] 分别对color,depth两个模态进行res0,res1,res2的计算；第75行， #[需填空]将3个模态 concat 融合,并实现MFE
      3. 完成填空后，可运行python model_baseline_Fusion.py 看网络输出是否正常。
      本次week2使用数据集是从CASIA-SURF中抽取的10组左右。
      完整数据需在week3后使用，同学们可预先由此地址下载：
          链接：https://pan.baidu.com/s/1-RDeHj0Z9bAVQzX1xrNU8Q  提取码：ay1y 
          CASIA-SURF数据集，包括了录制的视频、train、test、valid及其相应的标签。

   week2课程资料：
       1. facebagnet论文：/week2/facebagnet.pdf

其他资料：
    
    FPS3000人脸关键点：https://zhuanlan.zhihu.com/p/147390611
    8000点人脸关键点：https://zhuanlan.zhihu.com/p/62954487
    1000点人脸关键点：https://github.com/Single430/FaceLandmark1000
    关键点代码：https://medium.com/analytics-vidhya/facial-landmarks-and-face-detection-in-python-with-opencv-73979391f30e

    特征融合可以尝试特征对齐，可借鉴自适应场景的目标检测思路：https://zhuanlan.zhihu.com/p/401952495
    
    dropout:https://zhuanlan.zhihu.com/p/150592505
    pytorch的auto grad功能：https://zhuanlan.zhihu.com/p/69294347
    仿射变换： https://www.zhihu.com/question/20666664
    仿射变换代码： https://github.com/anjiang2016/IntroCV/blob/main/part1/part1_class_code.py

```

##  week19/3
```
CV名企实战 :  FaceBagNet工程代码:在baseline的基础上提升 
https://gitee.com/mingminglaoshi/famous-enterprises-fr-20210828
Pipeline:
1. week2作业
2. 提升思路：使用SE-NET 
3. 多模型的对比实验方法
4. 周期余弦退火代码方法[代码/理论待讲]

作业：
   [必做]1. 使用完整的数据集训练facebagnet.对比resnet18 和 SEResnet的效果，给出acer的对比结果。
   [可选]2. 使用周期余弦退火方法训练，并测试。
作业说明：
    1. 首先下载数据集：
          完整数据需在week3后使用，同学们可预先由此地址下载：
          链接：https://pan.baidu.com/s/1-RDeHj0Z9bAVQzX1xrNU8Q  提取码：ay1y 
          CASIA-SURF数据集，包括了录制的视频、train、test、valid及其相应的标签。
    2. 找到train_list.txt,val_private_list.txt,test_public_list.txt
    3. 修改文件week3/week3code-CVPR19-Face-Anti-spoofing/process/data_helper.py中关于数据地址的变量：DATA_ROOT,TRN_IMGS_DIR,TST_IMGS_DIR等。week3/week3code-CVPR19-Face-Anti-spoofing/process/data_helper.py 
    4. 修改完成后，运行命令：python data_fusion.py 可检查数据设置是否正确。
    5. 数据设置正确后，运行训练命令：CUDA_VISIBLE_DEVICES=0 python train_CyclicLR.py --model=model_A --image_mode=color --image_size=48，是否能训练起来。
    6. 调整超参数，训练一个基于SE-resnet的facebagnet,可使用代码：week3/week3code-CVRP19-Face-Anti-spoofing/model_fusion/model_baseline_SEFusion.py定义的模型。并统计acer.
    7. 把week2_answer中的model_baseline_Fusion.py 放在week3/week3code-CVRP19-Face-Anti-spoofing/model_fusion里，然后修改train_Fusion_CyclicLR.py相关代码，并训练，得到resnet_18版本的FaceBagNet的acer
    8. 对比两个模型的acer，完成作业。
    [可选] 9. 尝试每一个学习率的周期保存一次模型，然后用集成的方法测试。
    [可选] 10. 尝试周性的计算acer,并以acer为基准来保存模型。
课程资料：
    - week2课后作业答案：week3/week2_homework_answer
    - FaceBagNet工程代码：week3/week19code-CVPR19-Face-Anti-spoofing
    工程代码说明：
    -  单模态的facebagnet的训练代码: train_CyclicLR.py 
    -  三模态的facebagnet的训练代码: train_Fusion_CyclicLR.py 
    -  训练命令样例：run.sh
    -  数据准备代码所在文件夹：process
    -  模型准备代码所在文件夹：model,model_fusion
    -  周期余弦退火算法实现代码所在文件夹：loss
    -  输出log文件所在文件夹：models
    -  指标计算代码：metric.py,submission.py
    -  其他有用函数收集文件：utils.py

遗留内容资料：
    - resnext资料：https://zhuanlan.zhihu.com/p/51075096
    - resnext中的核心模块：分组卷积:https://zhuanlan.zhihu.com/p/226448051
    - 学习率的循环余弦退火策略：论文：https://arxiv.org/abs/1608.03983 ， SGDR:Stochastic Gradient Descent with Warm Restarts
    - 余弦退火公式解析：https://zhuanlan.zhihu.com/p/336673856

Google Colab GPU： 
    - https://mp.weixin.qq.com/s/gkd1OFEROO-z-_yXEVqAuw
    - https://mp.weixin.qq.com/s/_lmkN_TDcmWYK0B4urujag

```
    
## week20/4 
```
CV名企实战 :  消融实验以及模型压缩
https://gitee.com/mingminglaoshi/famous-enterprises-fr-20210828
Pipeline:
1. week18[week2]课堂遗留以及作业
2. 将活体检测模型使用在产品中 
3. 模型压缩：训练完成后再裁减
4. 基于L1 norm 的模型压缩

作业：
   [必做]1. 将训练好的活体检测模型使用到人脸识别系统中。
   [可选]2. 对自己在week3中训练的模型进行L1 norm Prune,并给出压缩后的FLOP和acer对比。
作业说明：
    - 必做作业建议
    1. 建议使用week1的课后作业以dlib为基础做的人脸识别系统为baseline.获取其人脸检测后的结果或人脸对齐后的结果，输入到活体检测模型中，给出结果。
    2. 为了更好的演示，建议以camera/视频/若干图片 作为输入。系统对输入的图片进行人脸检测，人脸对齐，活体检测，提取人脸特征，然后那这个特征和我们预测的目标人脸进行比对。
    3. 建议重新训练一个RGB单模态的活体检测模型,因为我们采集近红外图片和深度图图片不太方便。
    4. 作业的参考代码为：week4_homework_face_recognize.py , 90行，100行需要填写相应活体检测模型的是使用代码，初始化代码。133为活体检测模型的使用代码。
    5. python week4_homework_face_recognize.py 可正常运行，结果如下图4.1. 
    6. 代码默认是读取摄像头，如果摄像头不可用，可用老师提供的视频week4_videl3.mov作为输入。
    - 可选作业建议
    1. 首先找到代码中所要裁减的层[可选channel数最多那一层]的每个卷积组。
    2. 计算每个卷积组的 absolute sum S。
    3. 裁减掉50%的卷积组。
    4. 统计出裁减后的acre

课程资料：
    1 必做业务的代码方面，参考https://gitee.com/mingminglaoshi/famous-enterprises-fr-20210828 week1，week2,week3的代码，将代码组合在一起即可
    2 模型裁减的论文：PRUNING FILTERS FOR EFFICIENT CONVNETS:week20/PRUNING_FILTERS_FOR_EFFICIENT_CONVNETS.pdf
``` 
- 图4.1
![输入图片说明](https://images.gitee.com/uploads/images/2020/1020/140741_74934860_7401441.png "屏幕截图.png")

## week21/5
```
CV名企实战 :  Face Recognize 技术综述以及评价办法
https://gitee.com/mingminglaoshi/famous-enterprises-fr-20210828
Pipeline:
1. week20/4 作业
2. 如何在人群中找到“张三“ 
3. 构造FaceID:facenet 
4. LFW 与 vggface2
5. 等错误率(EER) 与 ROC 

作业：
   1. 完成代码填空，使用triplet loss跑通人脸识别器的小样本的训练代码week5/week5_homework.py。
   
作业说明：
    1. 在week5/triplet_loss.py 的 13行位置处，填写代码，完成triplet loss的内部计算细节。
    2. 在week5/week5_homework.py 的 # 在159行处，调用triplet_loss完成loss的计算。
    3。填写完成后运行办法：python week5_homework.py 

课程资料：
    1 week5/facenet.pdf, facenet这个网络论文
    2 triplet loss 论文实现：https://www.cnblogs.com/shensobaolibin/p/12600236.html
    3 LFW 数据库：http://vis-www.cs.umass.edu/lfw/#information
    4 VGG2数据库中文参考资料：https://blog.csdn.net/shaoxiaohu1/article/details/79007477
    5 VGGface2数据下载页面：http://www.robots.ox.ac.uk/~vgg/data/vgg_face2/
 week5文件夹下文件说明：
    1 week5/week4_answer:week4必做作业参考代码，实现将训练好的模型使用到人脸识别系统中。
    2 week5/week4_answer_2/FaceAnti_20201106.py:week4选做作业参考代码，实现剪切50%的卷积核。目前已实现卷积层的剪裁，配套bn,fc层待实现。
    1 文件夹week5/Datasets内为本次小样本训练的数据集。原始数据集需要人脸对齐和三元子生成，所需代码均在此文件夹下。
    2 文件夹week5/train_dataset.py 负责数据的处理和加载。这部分比较复杂，没有作为作业内容。完成作业后有精力的同学可以是试着理解一下这个代码。   
``` 

## week22/6
```
CV名企实战 : week06 Face embedding 的提升之路
https://gitee.com/mingminglaoshi/famous-enterprises-fr-20210828

Pipeline:
1. week5 作业:使用triplet loss跑通人脸识别器的小样本的训练代码
2. FaceNet  
3. VGGFace 
4. Center Loss
5. cos face 
6. arc face
7. week06 homework 

作业：
   1. 消融实验：对比不同embedding dim时模型准确率。
作业建议步骤：
    - 综合来说，就是在week5作业的基础上，更换训练数据集，添加测试数据集与代码。
    1. 训练数据集选择：VGGFACE2 的训练集 或者 VGGFACE2的测试集
     - 下载完成vggfrace2_tain.zip解压缩，得到vggface2_train文件夹
     - 由于人脸检测，对齐需要预先处理，所以我们运行week6/image_processing.py，对图片进行检测对齐处理
     - 这个时间耗时会非常长，注意时间安排。
     - 代码功能一：对齐后的图片保存到vggface2_train_notmask文件夹内
     - 代码功能二：对齐后的图片加口罩，保存到vggface2_train_mask文件夹内
     - 再运行make_csv_file.py,生成csv文件，为生成triplet做准备。
     - 运行 train_dataset.py 检查数据集是否正常。

    2. 测试数据集选择：lfw所有数据,
     - 下载方法：打开http://vis-www.cs.umass.edu/lfw/#download，
     - 下载All images aligned with funneling，
     - 具体下载地址为：http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz
     - 之后再下载文件pairs.txt,地址为：http://vis-www.cs.umass.edu/lfw/pairs.txt
     - pairs.txt文件是图片对文件，含有测试的图片对，以及标注。
     - pairs.txt文件的详细信息说明在readme里：http://vis-www.cs.umass.edu/lfw/README.txt
     - 下载完成后，编写dataset_lfw.py文件，配合torchvision.dataloader对测试数据进行读取
     - 参考代码位置在：week6/dataset_lfw.py 
    3. 训练代码：可在week5作业的基础上修改得到。
     - 这里需要添加 保存模型功能。方便测试是调用。
    4. 测试代码：week6/week6_test.py,其内调用的具体计算evaluate_lfw函数在代码 eval_lfw_tool.py里。
     - 修改week6_test.py 里的模型路径，然后运行测试
    5. 以上训练数据与代码，测试数据与代码都准备好后，即可进行消融实验。
     - 修改embedding的dim为256,训练模型，测试模型，记录auc,acc 
     - 修改embedding的dim为64,训练模型，测试模型，记录auc,acc 
       

课程资料：
    1. L2 Softmax Loss:week06/L2-constrained Softmax Loss for Discriminative Face Verification.pdf
    2. arcface paper: week06/arcface180107698.pdf
    3. cosface paper: week06/cosface1801.pdf
    4. vggface paper: week06/vggface.pdf
    5. VGGface :http://www.robots.ox.ac.uk/~vgg/software/vgg_face/
    6. 人脸识别数据集lfw数据集评价代码以及代码详解：https://zhuanlan.zhihu.com/p/269207802  
``` 

## week23/7
```
CV名企实战 : week07 注意力机制以及人脸识别工程
https://gitee.com/mingminglaoshi/famous-enterprises-fr-20210828

Pipeline:
1. week06作业以及triplet使用技巧
2. 遮挡人脸识别：Attention机制
3. week07 作业以及工程代码 

作业：
   1. 将CBAM加入到Face embedding model训练出一个可识别戴口罩人脸的人脸识别模型
作业建议步骤：
    - 综合来说，就是在week06作业的基础上，在训练集中添加戴口罩的数据集。
    1. 训练数据集选择：VGGFACE2 的训练集 或者 VGGFACE2的测试集
     - 下载完成vggfrace2_test.zip解压缩，得到vggface2_train文件夹
     - 由于人脸检测，对齐需要预先处理，所以我们运行week06/image_processing.py，对图片进行检测对齐加口罩处理
     - 这个时间耗时会非常长，注意时间安排。
     - 代码功能一：对齐后的图片保存到vggface2_train_notmask文件夹内
     - 代码功能二：对齐后的图片加口罩，保存到vggface2_train_mask文件夹内
     - 再运行make_csv_file.py,生成csv文件，为生成triplet做准备。
     - 运行 train_dataset.py 检查数据集是否正常。

    2. 训练代码：可在week06作业的基础上修改得到。
     - 两种attention代码代码参考：https://github.com/shiheyingzhe/Mask_face_recognitionZ/blob/master/Models/CBAM_Face_attention_Resnet_maskV1.py  39行，57行
     - 这里需要实现CABM模型的channel wise attention module和 point wise attention module.
    3. 如作业中遇到困难，可参考工程代码，
     - 版本一：https://github.com/HouchangX-AI/Mask-face-recognition 
     - 版本二：https://github.com/shiheyingzhe/Mask_face_recognitionZ  
     - 版本三cpu/gpu兼容版本：https://gitee.com/anjiang2020_admin/mfr-mask-face-recognition      

课程资料：
    1. 真实遮挡人脸数据集：https://github.com/X-zhangyang/Real-World-Masked-Face-Dataset
    2. CABM paper: week07/CBAM.pdf  
    
``` 

## week24/8

```
CV名企实战 : week08 大规模人脸识别落地方法sdk
https://gitee.com/mingminglaoshi/famous-enterprises-fr-20210828
Pipeline:
1. week08作业
2. 一般常用落地方法
3. Web server：model arts一键发布
4. 落地到嵌入式设备（手机，开发板）
5. 封装成pipy:pip install xxx

作业：
   1. week08作业：把在week08训练好的模型放入week4的作业里，替代dlib人脸识别系统中的人脸识别模型。至此，我们完成了人脸识别系统中，两个模型的从头训练：活体检测模型，人脸比对模型。
作业建议思路
    - 综合来说，主要是把训练好的模型保存到文件中，然后单独写一个使用模型的文件inference.py。
    - 也可以将inference.py封装成pypi的package,上传到pypi平台上。
    
课程资料：
    1. webserver部署工程代码：https://gitee.com/anjiang2020_admin/bd_cv3_webserver_demo
    2. websever 前端代码学习：https://www.w3school.com.cn/html/index.asp
    3. webserver 后端,python后端：建立自己的第一个网站：Django:https://docs.djangoproject.com/zh-hans/2.0/intro/tutorial01/
    4. pytorch落地到android上：https://pytorch.org/mobile/android/
    5. pytorch落地到ios上：https://pytorch.org/mobile/ios/
    6. 落地综述：https://zhuanlan.zhihu.com/p/54665674
    7. pytorch通过onnx来落地：https://zhuanlan.zhihu.com/p/346511883
    7. 不使用任何库来落地到ios上的工程demo:https://github.com/anjiang2016/MFace
    8. python 程序落地pip install 的办法：https://www.jianshu.com/p/f3afc88860cb  
课程资料：
    pipproject：制作pypi包的示例代码
    
```